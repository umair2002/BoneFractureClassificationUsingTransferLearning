{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6rOjzc_iF1k"
      },
      "source": [
        "**Mount Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVLIJb3dsByK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxjuiykRrfBy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y4XF4TNp9ok",
        "outputId": "a666152d-dc9b-4d25-92ed-52879c06676c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bS4MqrRtUL3"
      },
      "source": [
        "**Function and library loading**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle  # Import the shuffle function\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\n",
        "# Function to load images from folder and apply preprocessing\n",
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        img = cv2.resize(img, (224, 224))  # Resize to (224, 224)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7zeQ9MNSRM53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing dataset to use**"
      ],
      "metadata": {
        "id": "h66icgo73Vtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset\n",
        "training_folder_path = '/content/drive/MyDrive/BoneFractureDataset/archive/train'\n",
        "testing_folder_path = '/content/drive/MyDrive/BoneFractureDataset/archive/val'\n",
        "\n",
        "# load fractured and not fractured images from training and testing sets\n",
        "train_fractured_images = load_images_from_folder(os.path.join(training_folder_path, 'fractured'))\n",
        "train_not_fractured_images = load_images_from_folder(os.path.join(training_folder_path, 'not fractured'))\n",
        "\n",
        "test_fractured_images = load_images_from_folder(os.path.join(testing_folder_path, 'fractured'))\n",
        "test_not_fractured_images = load_images_from_folder(os.path.join(testing_folder_path, 'not fractured'))\n",
        "\n",
        "# combine fractured images\n",
        "all_fractured_images = np.concatenate((train_fractured_images, test_fractured_images), axis=0)\n",
        "all_fractured_labels = np.ones(all_fractured_images.shape[0])\n",
        "\n",
        "# combine not fractured images\n",
        "all_not_fractured_images = np.concatenate((train_not_fractured_images, test_not_fractured_images), axis=0)\n",
        "all_not_fractured_labels = np.zeros(all_not_fractured_images.shape[0])\n",
        "\n",
        "# combine all images and labels and shuffle the data\n",
        "all_images = np.concatenate((all_fractured_images, all_not_fractured_images), axis=0)\n",
        "all_labels = np.concatenate((all_fractured_labels, all_not_fractured_labels), axis=0)\n",
        "all_images, all_labels = shuffle(all_images, all_labels, random_state=42)\n",
        "\n",
        "# split the shuffled data into training, validation, and testing sets (60% - 20% - 20% split)\n",
        "train_images, temp_images, train_labels, temp_labels = train_test_split(all_images, all_labels, test_size=0.4, random_state=42)\n",
        "valid_images, test_images, valid_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "YCYWEfeoRNdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use ResNet50 pretrained on ImageNet for transfer learning**"
      ],
      "metadata": {
        "id": "u6oPbjly3n_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model pre-trained on ImageNet\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# custom classification layers added on top of pretrained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# create the final model\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op14-ADKRPnh",
        "outputId": "3b4e10ae-387e-4825-b54e-1393569e4b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train the model**"
      ],
      "metadata": {
        "id": "dujqBMCX3vhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with validation data\n",
        "model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels), epochs=20, batch_size=128)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "predictions = model.predict(test_images)\n",
        "rounded_predictions = np.round(predictions).flatten().astype(int)\n",
        "accuracy = accuracy_score(test_labels, rounded_predictions)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr7CeEXCRTiy",
        "outputId": "3ee4f754-dc6c-4fa3-c1a8-eda7a59985aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "45/45 [==============================] - 49s 644ms/step - loss: 0.6661 - accuracy: 0.6373 - val_loss: 0.4896 - val_accuracy: 0.7802\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 20s 452ms/step - loss: 0.4337 - accuracy: 0.7958 - val_loss: 0.3545 - val_accuracy: 0.8595\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 26s 578ms/step - loss: 0.3174 - accuracy: 0.8679 - val_loss: 0.2446 - val_accuracy: 0.9192\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 26s 583ms/step - loss: 0.2527 - accuracy: 0.9022 - val_loss: 0.2041 - val_accuracy: 0.9319\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 26s 587ms/step - loss: 0.2025 - accuracy: 0.9267 - val_loss: 0.1522 - val_accuracy: 0.9599\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 26s 582ms/step - loss: 0.1650 - accuracy: 0.9459 - val_loss: 0.1557 - val_accuracy: 0.9445\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.1302 - accuracy: 0.9614 - val_loss: 0.1021 - val_accuracy: 0.9731\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.1152 - accuracy: 0.9662 - val_loss: 0.0849 - val_accuracy: 0.9794\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.0964 - accuracy: 0.9727 - val_loss: 0.0786 - val_accuracy: 0.9799\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.0818 - accuracy: 0.9760 - val_loss: 0.0651 - val_accuracy: 0.9826\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 26s 589ms/step - loss: 0.0750 - accuracy: 0.9819 - val_loss: 0.0611 - val_accuracy: 0.9868\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 26s 588ms/step - loss: 0.0625 - accuracy: 0.9840 - val_loss: 0.0502 - val_accuracy: 0.9878\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 21s 470ms/step - loss: 0.0543 - accuracy: 0.9875 - val_loss: 0.0456 - val_accuracy: 0.9889\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 26s 587ms/step - loss: 0.0454 - accuracy: 0.9891 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.0434 - accuracy: 0.9898 - val_loss: 0.0377 - val_accuracy: 0.9926\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 26s 585ms/step - loss: 0.0420 - accuracy: 0.9900 - val_loss: 0.0469 - val_accuracy: 0.9847\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 0.0345 - val_accuracy: 0.9931\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 21s 472ms/step - loss: 0.0378 - accuracy: 0.9919 - val_loss: 0.0336 - val_accuracy: 0.9921\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 26s 588ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.0311 - val_accuracy: 0.9921\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 26s 584ms/step - loss: 0.0276 - accuracy: 0.9944 - val_loss: 0.0302 - val_accuracy: 0.9910\n",
            "60/60 [==============================] - 8s 99ms/step\n",
            "Test Accuracy: 0.9926043317485472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**"
      ],
      "metadata": {
        "id": "pZxxkwQN3zu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "import cv2\n",
        "import os\n",
        "# Print confusion matrix\n",
        "confusion = confusion_matrix(test_labels, rounded_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "\n",
        "report = classification_report(test_labels, rounded_predictions)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQicRWASX8Lc",
        "outputId": "66092146-1456-4cf0-c985-d938d20eccf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[922   2]\n",
            " [ 12 957]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99       924\n",
            "         1.0       1.00      0.99      0.99       969\n",
            "\n",
            "    accuracy                           0.99      1893\n",
            "   macro avg       0.99      0.99      0.99      1893\n",
            "weighted avg       0.99      0.99      0.99      1893\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model**"
      ],
      "metadata": {
        "id": "V8anYoYw32Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to the specified location\n",
        "save_path = '/content/drive/MyDrive/BoneFractureDataset/archive/pretrainedResmodelBoneFractureClassifier2.h5'\n",
        "model.save(save_path)\n"
      ],
      "metadata": {
        "id": "SRXZSpOpXbjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}